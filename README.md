# Hierarchical Recurrent Encoder-Decoder 

An extension on the Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion, our implementation is in Tensorflow and uses an attention mechanism.

**The original paper:** [A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion](https://arxiv.org/abs/1507.02221)
**Our final report: ** [HRED with Attention](https://github.com/tscheepers/hred-attention-tensorflow/blob/master/docs/report_hred_with_attention.pdf)

**The original Theano implementation:** [sordonia/hred-qs](https://github.com/sordonia/hred-qs)

- **Data:** 
  - [Raw AOL dataset](https://www.dropbox.com/s/thuv05pl3wyz6lq/aol-data.tar?dl=0)
  - [Chuncked pre-processed data](https://www.dropbox.com/sh/zm430xgouaibo5q/AABO9OuWDlkqMI5nYM9vgS80a?dl=0)
  - [Data to feed into the model](https://www.dropbox.com/sh/d9ukeq9uptamik8/AACTfqrnP2erci0N-A3cxu0Fa?dl=0)
  
Implementation by: [Maartje ter Hoeve](https://github.com/maartjeth), [JÃ¶rg Sander](https://github.com/toologicbv), [Maurits Bleeker](https://github.com/MBleeker) and [Thijs Scheepers](https://github.com/tscheepers)
